package pkmx.lcamera

import collection.JavaConversions._
import java.io.{File, FileNotFoundException, FileOutputStream}
import java.nio.ByteBuffer
import java.text.DecimalFormat
import scala.concurrent.{Promise, Channel, ExecutionContext, Future}
import scala.collection.immutable.Vector
import scala.language.{existentials, implicitConversions, reflectiveCalls}
import scala.util.Try
import scala.util.control.Exception.ignoring
import scala.util.control.NonFatal

import android.animation._
import android.app.Activity.{RESULT_CANCELED, RESULT_OK}
import android.content.{Intent, DialogInterface, Context}
import android.graphics._
import android.graphics.drawable.{Drawable, ColorDrawable}
import android.hardware.Camera.{ACTION_NEW_PICTURE, ACTION_NEW_VIDEO}
import android.hardware.camera2._
import android.hardware.camera2.CameraCharacteristics._
import android.hardware.camera2.CameraMetadata._
import android.hardware.camera2.CaptureRequest._
import android.hardware.camera2.params._
import android.media.{MediaRecorder, Image, MediaScannerConnection, ImageReader}
import android.media.ImageReader.OnImageAvailableListener
import android.media.MediaScannerConnection.OnScanCompletedListener
import android.net.Uri
import android.os._
import android.provider.MediaStore
import android.text.format.Time
import android.view._
import android.view.animation.{Animation, TranslateAnimation}
import android.view.animation.Animation.AnimationListener
import android.widget._
import android.widget.ImageView.ScaleType
import android.util.Size

import com.melnykov.fab.FloatingActionButton
import com.github.rahatarmanahmed.cpv.CircularProgressView
import org.scaloid.common.{runOnUiThread => _, _}
import rx._
import rx.ops._

object Utils {
  implicit val execCtx = ExecutionContext.fromExecutor(AsyncTask.THREAD_POOL_EXECUTOR)

  type Fab = FloatingActionButton

  val slideUpShow = (v: View) => {
    v.startAnimation(new TranslateAnimation(
      Animation.RELATIVE_TO_SELF, 0,
      Animation.RELATIVE_TO_SELF, 0,
      Animation.RELATIVE_TO_SELF, 1,
      Animation.RELATIVE_TO_SELF, 0) {
      setDuration(300)
      setAnimationListener(new AnimationListener {
        override def onAnimationEnd(anim: Animation): Unit = { v.visibility = View.VISIBLE }
        override def onAnimationStart(anim: Animation): Unit = {}
        override def onAnimationRepeat(anim: Animation): Unit = {}
      })
    })
    v.enable()
  }

  val slideDownHide = (v: View) => {
    v.startAnimation(new TranslateAnimation(
      Animation.RELATIVE_TO_SELF, 0,
      Animation.RELATIVE_TO_SELF, 0,
      Animation.RELATIVE_TO_SELF, 0,
      Animation.RELATIVE_TO_SELF, 1) {
      setDuration(300)
      setAnimationListener(new AnimationListener {
        override def onAnimationEnd(anim: Animation): Unit = { v.visibility = View.INVISIBLE }
        override def onAnimationStart(anim: Animation): Unit = {}
        override def onAnimationRepeat(anim: Animation): Unit = {}
      })
    })
    v.disable()
  }

  def NoneVar[T] = Var[Option[T]](None)

  class STextureView(implicit ctx: Context, loggerTag: LoggerTag) extends TextureView(ctx) with TraitView[TextureView] {
    val basis = this

    private[this] val surfaceTextureVar = NoneVar[SurfaceTexture]
    def surfaceTexture: Rx[Option[SurfaceTexture]] = surfaceTextureVar

    setSurfaceTextureListener(new TextureView.SurfaceTextureListener {
      override def onSurfaceTextureAvailable(texture: SurfaceTexture, width: Int, height: Int): Unit = {
        debug(s"Surface texture available: $texture")
        surfaceTextureVar() = Option(texture)
      }

      override def onSurfaceTextureSizeChanged(st: SurfaceTexture, w: Int, h: Int) = onSurfaceTextureAvailable _
      override def onSurfaceTextureUpdated(st: SurfaceTexture): Unit = {}
      override def onSurfaceTextureDestroyed(st: SurfaceTexture) = {
        debug("Surface texture destroyed")
        surfaceTextureVar() = None
        true
      }
    })
  }

  class SSwitch(implicit ctx: Context) extends Switch(ctx) with TraitCompoundButton[Switch] {
    val basis = this
  }

  class MyMediaRecorder(val vc: VideoConfiguration, orientation: Int) extends MediaRecorder {
    import MyMediaRecorder._
    var realFilePath = tmpFilePath

    setVideoSource(2) // SURFACE
    setAudioSource(5) // CAMCORDER
    setOutputFormat(2) // MPEG_4
    setAudioChannels(2)
    setAudioEncodingBitRate(384000)
    setAudioSamplingRate(44100)
    setVideoSize(vc.width, vc.height)
    setVideoEncodingBitRate(vc.bitrate)
    setVideoFrameRate(vc.fps)
    setOrientationHint(orientationToDegree(orientation))
    setOutputFile(tmpFilePath)
    setVideoEncoder(2) // H264
    setAudioEncoder(3) // AAC
    prepare()
  }

  object MyMediaRecorder {
    val tmpFilePath = createPathIfNotExist(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM) + "/Camera/") + ".lcamera.mp4"
  }

  def renameFile(src: String, dst: String): Unit = { new File(src).renameTo(new File(dst)) }

  def orientationToDegree(orientation: Int) = orientation match {
    case Surface.ROTATION_0 => 90
    case Surface.ROTATION_90 => 0
    case Surface.ROTATION_180 => 270
    case Surface.ROTATION_270 => 180
    case _ => 0
  }

  def createPathIfNotExist(path: String): String = {
    val file = new File(path)
    if (!file.exists()) {
      file.mkdirs()
    }
    path
  }

  implicit class RichSize(size: Size) {
    def <=(rhs: Size) = size.getWidth <= rhs.getWidth && size.getHeight <= rhs.getHeight
  }

  sealed case class VideoConfiguration(width: Int, height: Int, fps: Int, bitrate: Int) {
    override def toString: String = s"${width}x${height}x$fps @ ${new DecimalFormat("#.#").format(bitrate.toDouble / 1000000)}mbps"
  }

  sealed trait Observable extends AutoCloseable {
    var obses: List[Obs] = List()

    def observe(obs: Obs): Obs = {
      obses = obs :: obses
      obs
    }

    override def close(): Unit = {
      obses foreach { _.kill() }
    }
  }

  def byteBufferToByteArray(bb: ByteBuffer): Array[Byte] = {
    val bytes = new Array[Byte](bb.remaining())
    bb.get(bytes, 0, bb.remaining())
    bytes
  }

  def mediaScan(filePath: String, action: String)(implicit ctx: Context): Unit = {
    MediaScannerConnection.scanFile(ctx, Array(filePath), null, new OnScanCompletedListener {
      override def onScanCompleted(path: String, uri: Uri): Unit = {
        if (uri != null) {
          ctx.sendBroadcast(new Intent(action, uri))
        } else {
          ctx.sendBroadcast(new Intent(action, Uri.fromFile(new File(path))))
        }
      }
    })
  }

  implicit class RichFuture[+T](val future: Future[T]) {
    def toOption: Option[T] = future.value flatMap { _.toOption }
  }

  implicit class RichRxOps[+T](val rx: Rx[T]) {
    def withFilter(f: T => Boolean) = rx filter f
  }

  // See: https://github.com/pkmx/lcamera/issues/138
  implicit class RichCaptureRequestBuilder(val builder: CaptureRequest.Builder) {
    def set_[T, U](k: CaptureRequest.Key[T], v: U)(implicit ev: U => T): Unit = {
      builder.set(k, implicitly[T](v))
    }
  }

  def runOnUiThread[T](f: => T): Future[T] = {
    if (uiThread == Thread.currentThread) {
      Future.fromTry(Try(f))
    } else {
      val p = Promise[T]()
      handler.post(new Runnable {
        override def run(): Unit = p.complete(Try(f))
      })
      p.future
    }
  }
}

import Utils._

class LCameraManager(implicit private[this] val cameraManager: CameraManager, loggerTag: LoggerTag, ctx: Context) {
  def openLCamera (cameraId: String) : Rx[Option[LCamera]] = {
    val lcamera = NoneVar[LCamera]

    cameraManager.openCamera(cameraId, new CameraDevice.StateCallback {
      override def onOpened(device: CameraDevice): Unit = {
        debug(s"Camera opened: $device")
        lcamera() = Option(new LCamera(device))
      }

      override def onError(device: CameraDevice, error: Int): Unit = {
        debug(s"Camera error: $device, $error")
        longToast(s"Unable to open camera ($error)")
        lcamera() foreach { _.close() }
      }

      override def onDisconnected(device: CameraDevice): Unit = {
        debug(s"Camera disconnected: $device")
        lcamera() foreach { _.close() }
      }

      override def onClosed(device: CameraDevice): Unit = {
        debug(s"Camera closed: $device")
        lcamera() = None
      }
    }, null)

    lcamera
  }
}

object LCamera {
  sealed trait RawOrYuv
  case object Raw extends RawOrYuv
  case object Yuv extends RawOrYuv

  sealed trait Focus
  case object AutoFocus extends Focus
  case class ManualFocus(focusDistance: Float) extends Focus

  sealed trait Exposure
  case object AutoExposure extends Exposure
  case class ManualExposure(exposureDuration: Long, iso: Int) extends Exposure
}

class LCamera (private[this] val camera: CameraDevice) (implicit cameraManager: CameraManager, loggerTag: LoggerTag, ctx: Context) extends Observable with AutoCloseable {
  import LCamera._

  val characteristics = cameraManager.getCameraCharacteristics(camera.getId)
  val streamConfigurationMap = characteristics.get(SCALER_STREAM_CONFIGURATION_MAP)
  val activeArraySize = characteristics.get(SENSOR_INFO_ACTIVE_ARRAY_SIZE)
  val minFocusDistance = characteristics.get(LENS_INFO_MINIMUM_FOCUS_DISTANCE)
  val isoRange = characteristics.get(SENSOR_INFO_SENSITIVITY_RANGE)
  val exposureTimeRange = characteristics.get(SENSOR_INFO_EXPOSURE_TIME_RANGE)

  val yuvSizes = streamConfigurationMap.getOutputSizes(ImageFormat.YUV_420_888)
  val rawSize = streamConfigurationMap.getOutputSizes(ImageFormat.RAW_SENSOR)(0)
  val jpegSize = streamConfigurationMap.getOutputSizes(ImageFormat.JPEG).filter(_ <= rawSize)(0)
  val yuvSize = yuvSizes.filter(_ <= rawSize)(0)
  val minFrameDuration = streamConfigurationMap.getOutputMinFrameDuration(ImageFormat.RAW_SENSOR, rawSize)
  val rawFps = if (minFrameDuration != 0) 1000000000 / minFrameDuration else Int.MaxValue

  private[this] val captureSessionVar = NoneVar[Future[CaptureSession]]
  def captureSession: Rx[Option[Future[CaptureSession]]] = captureSessionVar

  sealed trait CaptureSession extends AutoCloseable {
    protected[this] val session: CameraCaptureSession
    protected[this] val previewSurface: Surface

    val lastFocusDistanceVar = Var(0.0f)
    val lastExposureTimeVar = Var(1000000000l)
    val lastIsoVar = Var(100)
    def lastFocusDistance: Rx[Float] = lastFocusDistanceVar
    def lastExposureTime: Rx[Long] = lastExposureTimeVar
    def lastIso: Rx[Int] = lastIsoVar

    protected[this] def setupRequest(request: CaptureRequest.Builder, focus: Focus, exposure: Exposure): Unit = {
      request.set_(CONTROL_MODE, CONTROL_MODE_AUTO)
      focus match {
        case AutoFocus =>
          request.set_(CONTROL_AF_MODE, CONTROL_AF_MODE_AUTO)
        case ManualFocus(fd) =>
          request.set_(CONTROL_AF_MODE, CONTROL_AF_MODE_OFF)
          request.set_(LENS_FOCUS_DISTANCE, fd)
      }

      exposure match {
        case AutoExposure =>
          request.set_(CONTROL_AE_MODE, CONTROL_AE_MODE_ON)
        case ManualExposure(duration, iso) =>
          request.set_(CONTROL_AE_MODE, CONTROL_AE_MODE_OFF)
          request.set_(SENSOR_EXPOSURE_TIME, duration)
          request.set_(SENSOR_SENSITIVITY, iso)
      }
      request.set_(SENSOR_FRAME_DURATION, minFrameDuration)
    }

    def setupPreview(focus: Focus, exposure: Exposure): Unit = {
      debug(s"Starting preview using $session")
      val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)
      setupRequest(request, focus, exposure)

      request.addTarget(previewSurface)
      session.setRepeatingRequest(request.build(), new CameraCaptureSession.CaptureCallback {
        override def onCaptureCompleted(session: CameraCaptureSession, request: CaptureRequest, result: TotalCaptureResult): Unit = {
          lastFocusDistanceVar() = result.get(CaptureResult.LENS_FOCUS_DISTANCE)
          lastExposureTimeVar() = result.get(CaptureResult.SENSOR_EXPOSURE_TIME)
          lastIsoVar() = result.get(CaptureResult.SENSOR_SENSITIVITY)
        }
      }, null)
    }

    def triggerMetering(mr: MeteringRectangle, focus: Focus, exposure: Exposure): Unit = {
      debug(s"Triggering metering using $camera")
      val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW)

      focus match {
        case AutoFocus =>
          request.set_(CONTROL_AF_MODE, CONTROL_AF_MODE_AUTO)
          request.set_(CONTROL_AF_TRIGGER, CONTROL_AF_TRIGGER_START)
          request.set_(CONTROL_AF_REGIONS, Array[MeteringRectangle](mr))
        case ManualFocus(fd) =>
          request.set_(CONTROL_AF_MODE, CONTROL_AF_MODE_OFF)
          request.set_(LENS_FOCUS_DISTANCE, fd)
      }

      exposure match {
        case AutoExposure =>
          request.set_(CONTROL_AE_MODE, CONTROL_AE_MODE_ON)
          request.set_(CONTROL_AE_PRECAPTURE_TRIGGER, CONTROL_AE_PRECAPTURE_TRIGGER_START)
          request.set_(CONTROL_AE_REGIONS, Array[MeteringRectangle](mr))
        case ManualExposure(duration, iso) =>
          request.set_(CONTROL_AE_MODE, CONTROL_AE_MODE_OFF)
          request.set_(SENSOR_EXPOSURE_TIME, duration)
          request.set_(SENSOR_SENSITIVITY, iso)
      }
      request.addTarget(previewSurface)

      session.capture(request.build(), null, null)
    }
    override def close(): Unit = {
      session.close()
    }
  }

  private[this] def createSession(surfaces: List[Surface], onSuccess: CameraCaptureSession => CaptureSession): Unit = {
    if (!(captureSessionVar() exists { !_.isCompleted } )) {
      debug(s"Creating capture session using $camera $surfaces")
      captureSession() foreach { _ onSuccess { case s => s.close() } }

      val p = Promise[CaptureSession]()
      captureSessionVar() = Some(p.future)
      camera.createCaptureSession(surfaces, new CameraCaptureSession.StateCallback {
        override def onConfigured(session: CameraCaptureSession): Unit = {
          debug(s"Capture session configured: $session")
          p success onSuccess(session)
          captureSessionVar.propagate()
        }

        override def onConfigureFailed(session: CameraCaptureSession): Unit = {
          debug("Capture session configuration failed")
          p failure new RuntimeException
          captureSessionVar.propagate()
        }

        override def onClosed(session: CameraCaptureSession): Unit = {
          debug(s"Capture session closed: $session")
        }
      }, null)
    }
  }

  def openPhotoSession(previewSurface: Surface, maxImages: Int = 1): Unit = {
    val jpegImageReader = ImageReader.newInstance(jpegSize.getWidth, jpegSize.getHeight, ImageFormat.JPEG, maxImages)
    val rawImageReader = ImageReader.newInstance(rawSize.getWidth, rawSize.getHeight, ImageFormat.RAW_SENSOR, maxImages)
    createSession(List(previewSurface, jpegImageReader.getSurface, rawImageReader.getSurface), (session) => new PhotoSession(session, previewSurface, jpegImageReader, rawImageReader))
  }

  def openBurstSession(previewSurface: Surface, rawYuv: RawOrYuv, maxImages: Int = 7): Unit = {
    val imageReader = rawYuv match {
      case Raw => ImageReader.newInstance(rawSize.getWidth, rawSize.getHeight, ImageFormat.RAW_SENSOR, maxImages)
      case Yuv => ImageReader.newInstance(yuvSize.getWidth, yuvSize.getHeight, ImageFormat.YUV_420_888, maxImages)
    }
    createSession(List(previewSurface, imageReader.getSurface), (session) => new BurstSession(session, previewSurface, imageReader, rawYuv))
  }

  def openBulbSession(previewSurface: Surface): Unit = {
    val imageReader = ImageReader.newInstance(rawSize.getWidth, rawSize.getHeight, ImageFormat.RAW_SENSOR, 1)
    createSession(List(previewSurface, imageReader.getSurface), (session) => new BulbSession(session, previewSurface, imageReader))
  }

  def openVideoSession(previewSurface: Surface, vc: VideoConfiguration, orientation: Int): Unit = {
    val mr = new MyMediaRecorder(vc, orientation)
    createSession(List(previewSurface, mr.getSurface), (session) => new VideoSession(session, previewSurface, mr))
  }

  class PhotoSession (protected[this] val session: CameraCaptureSession, protected[this] val previewSurface: Surface, jpegImageReader: ImageReader, rawImageReader: ImageReader) extends CaptureSession {
    private [this] val capturingVar = Var(false)
    def capturing: Rx[Boolean] = capturingVar
    private [this] val jpegSurface = jpegImageReader.getSurface
    private [this] val rawSurface = rawImageReader.getSurface
    private [this] val jpegImageChannel = new Channel[Image]
    private [this] val rawImageChannel = new Channel[Image]

    jpegImageReader.setOnImageAvailableListener(new OnImageAvailableListener {
      override def onImageAvailable(reader: ImageReader): Unit = { jpegImageChannel.write(reader.acquireNextImage()) }
    }, null)

    rawImageReader.setOnImageAvailableListener(new OnImageAvailableListener {
      override def onImageAvailable(reader: ImageReader): Unit = { rawImageChannel.write(reader.acquireNextImage()) }
    }, null)

    def capture(focus: Focus, exposure: Exposure, orientation: Int, successHandler: (TotalCaptureResult, Image, Image) => Unit): Unit = {
      if (!capturing()) {
        debug(s"Starting capture using $camera")
        capturingVar() = true

        val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE)
        setupRequest(request, focus, exposure)
        request.set_(LENS_OPTICAL_STABILIZATION_MODE, LENS_OPTICAL_STABILIZATION_MODE_ON)
        request.set_(JPEG_QUALITY, 100.toByte)
        request.set_(JPEG_ORIENTATION, orientationToDegree(orientation))
        request.set_(STATISTICS_LENS_SHADING_MAP_MODE, STATISTICS_LENS_SHADING_MAP_MODE_ON) // Required for RAW capture
        List(previewSurface, jpegSurface, rawSurface) foreach request.addTarget

        debug(s"Capturing with $session")
        session.capture(request.build(), new CameraCaptureSession.CaptureCallback {
          override def onCaptureCompleted(session: CameraCaptureSession, request: CaptureRequest, result: TotalCaptureResult): Unit = {
            debug(s"Capture completed: " +
              s"focus = ${result.get(CaptureResult.LENS_FOCUS_DISTANCE)}/${request.get(LENS_FOCUS_DISTANCE)} " +
              s"iso = ${result.get(CaptureResult.SENSOR_SENSITIVITY)}/${request.get(SENSOR_SENSITIVITY)} " +
              s"exposure = ${result.get(CaptureResult.SENSOR_EXPOSURE_TIME)}/${request.get(SENSOR_EXPOSURE_TIME)}")

            val f = Future {
              val jpegImage = jpegImageChannel.read
              val rawImage = rawImageChannel.read

              successHandler(result, jpegImage, rawImage)

              jpegImage.close()
              rawImage.close()
            }
            f onFailure { case NonFatal(e) => e.printStackTrace() }
            f onComplete { _ => runOnUiThread { capturingVar() = false } }
          }

          override def onCaptureFailed(session: CameraCaptureSession, request: CaptureRequest, failure: CaptureFailure): Unit = {
            debug("Capture failed")
            capturingVar() = false
          }
        }, null)
      }
    }
  }

  class BurstSession (protected[this] val session: CameraCaptureSession, protected[this] val previewSurface: Surface, private[this] val imageReader: ImageReader, val rawYuv: RawOrYuv) extends CaptureSession {
    private[this] val capturingVar = Var(false)
    def capturing: Rx[Boolean] = capturingVar

    private [this] val surface = imageReader.getSurface
    private [this] val imageChannel = new Channel[Image]
    private [this] val resultChannel = new Channel[Either[TotalCaptureResult, CaptureFailure]]

    imageReader.setOnImageAvailableListener(new OnImageAvailableListener {
      override def onImageAvailable(reader: ImageReader): Unit = { imageChannel.write(reader.acquireNextImage()) }
    }, null)

    case class Request(focus: Focus, exposure: Exposure, handler: (TotalCaptureResult, Image) => Unit)
    def burstCapture(requests: List[Request], orientation: Int): Unit = {
      if (!capturing()) {
        debug(s"Starting burst capture using $camera")
        capturingVar() = true

        val builders = requests map { r => {
          val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE)
          setupRequest(request, r.focus, r.exposure)
          request.set_(LENS_OPTICAL_STABILIZATION_MODE, LENS_OPTICAL_STABILIZATION_MODE_ON)
          if (rawYuv == Raw) {
            request.set_(STATISTICS_LENS_SHADING_MAP_MODE, STATISTICS_LENS_SHADING_MAP_MODE_ON) // Required for RAW capture
          }
          request.addTarget(surface)
          request
        } }

        debug(s"Burst capturing with $session")
        session.captureBurst(builders map { _.build() }, new CameraCaptureSession.CaptureCallback {
          override def onCaptureCompleted(session: CameraCaptureSession, request: CaptureRequest, result: TotalCaptureResult): Unit = {
            debug(s"Capture completed: " +
              s"focus = ${result.get(CaptureResult.LENS_FOCUS_DISTANCE)}/${request.get(LENS_FOCUS_DISTANCE)} " +
              s"iso = ${result.get(CaptureResult.SENSOR_SENSITIVITY)}/${request.get(SENSOR_SENSITIVITY)} " +
              s"exposure = ${result.get(CaptureResult.SENSOR_EXPOSURE_TIME)}/${request.get(SENSOR_EXPOSURE_TIME)}")

            resultChannel.write(Left(result))
          }

          override def onCaptureFailed(session: CameraCaptureSession, request: CaptureRequest, failure: CaptureFailure): Unit = {
            debug("Capture failed")
            resultChannel.write(Right(failure))
          }
        }, null)

        val f = Future {
          for (r <- requests) {
            resultChannel.read match {
              case Left(result) =>
                val image = imageChannel.read
                r.handler(result, image)
                image.close()
              case Right(_) =>
            }
          }
        }

        f onFailure { case NonFatal(e) => e.printStackTrace() }
        f onComplete { _ => runOnUiThread { capturingVar() = false } }
      }
    }
  }

  class BulbSession (protected[this] val session: CameraCaptureSession, protected[this] val previewSurface: Surface, private[this] val imageReader: ImageReader) extends CaptureSession {
    private[this] var keepCapturing = false
    private[this] val capturingVar = Var(false)
    def capturing: Rx[Boolean] = capturingVar

    private [this] val surface = imageReader.getSurface
    private [this] val imageChannel = new Channel[Image]

    imageReader.setOnImageAvailableListener(new OnImageAvailableListener {
      override def onImageAvailable(reader: ImageReader): Unit = { imageChannel.write(reader.acquireNextImage()) }
    }, null)

    def startCapturing(focus: Focus, exposure: Exposure, orientation: Int, handler: (TotalCaptureResult, Image, Int) => Unit): Unit = {
      if (!capturing()) {
        debug(s"Starting bulb capture using $camera")
        capturingVar() = true
        keepCapturing = true

        lazy val captureOne: Int => Unit = (n: Int) => {
          if (keepCapturing) {
            val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_STILL_CAPTURE)
            setupRequest(request, focus, exposure)
            request.set_(LENS_OPTICAL_STABILIZATION_MODE, LENS_OPTICAL_STABILIZATION_MODE_ON)
            request.set_(STATISTICS_LENS_SHADING_MAP_MODE, STATISTICS_LENS_SHADING_MAP_MODE_ON) // Required for RAW capture
            List(previewSurface, surface) foreach request.addTarget

            debug(s"bulb capturing with $session")
            session.capture(request.build, new CameraCaptureSession.CaptureCallback {
              override def onCaptureCompleted(session: CameraCaptureSession, request: CaptureRequest, result: TotalCaptureResult): Unit = {
                debug(s"Capture completed: " +
                  s"focus = ${result.get(CaptureResult.LENS_FOCUS_DISTANCE)}/${request.get(LENS_FOCUS_DISTANCE)} " +
                  s"iso = ${result.get(CaptureResult.SENSOR_SENSITIVITY)}/${request.get(SENSOR_SENSITIVITY)} " +
                  s"exposure = ${result.get(CaptureResult.SENSOR_EXPOSURE_TIME)}/${request.get(SENSOR_EXPOSURE_TIME)}")

                Future {
                  val image = imageChannel.read
                  handler(result, image, n)
                  image.close()

                  runOnUiThread {
                    if (keepCapturing) {
                      captureOne(n + 1)
                    } else {
                      capturingVar() = false
                    }
                  }
                }
              }

              override def onCaptureFailed(session: CameraCaptureSession, request: CaptureRequest, failure: CaptureFailure): Unit = {
                debug("Capture failed")
                capturingVar() = false
                keepCapturing = false
              }
            }, null)
          }
        }

        captureOne(0)
      }
    }

    def stopCapturing(): Unit = {
      keepCapturing = false
    }
  }

  class VideoSession (protected[this] val session: CameraCaptureSession, protected[this] val previewSurface: Surface, private[this] val mr: MyMediaRecorder) extends CaptureSession {
    private[this] val recordingVar = Var(false)
    def recording: Rx[Boolean] = recordingVar

    override def setupPreview(focus: Focus, exposure: Exposure): Unit = {
      debug(s"Starting preview using $session")
      val request = camera.createCaptureRequest(CameraDevice.TEMPLATE_RECORD)
      setupRequest(request, focus, exposure)

      List(previewSurface, mr.getSurface) foreach request.addTarget
      session.setRepeatingRequest(request.build(), null, null)
    }

    def startRecording(focus: Focus, exposure: Exposure): Unit = {
      setupPreview(focus, exposure)

      debug("Starting recording")
      val time = new Time
      time.setToNow()
      mr.realFilePath = Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM) + "/Camera/" + time.format("VID_%Y%m%d_%H%M%S.mp4")
      mr.start()
      recordingVar() = true
    }

    def stopRecording(): Unit = {
      debug("Stop recording")
      try {
        mr.stop()
        renameFile(MyMediaRecorder.tmpFilePath, mr.realFilePath)
        mediaScan(mr.realFilePath, ACTION_NEW_VIDEO)
      } catch {
        case e: RuntimeException => new File(MyMediaRecorder.tmpFilePath).delete()
      }
      recordingVar() = false
    }

    override def close(): Unit = {
      super.close()
      mr.reset()
      mr.release()
    }
  }

  override def close(): Unit = {
    super.close()
    captureSession() foreach { _ onSuccess { case s => s.close() } }
    camera.close()
  }
}

object Colors {
  val blueA400 = Color.rgb(0x29, 0x79, 0xff)
  val grey300 = Color.rgb(0xe0, 0xe0, 0xe0)
  val grey600 = Color.rgb(0x75, 0x75, 0x75)
  val grey800 = Color.rgb(0x42, 0x42, 0x42)
  val orange500 = Color.rgb(0xff, 0x98, 0x00)
  val holoRed = Color.rgb(0xff, 0x44, 0x44)
  val holoGreen = Color.rgb(0x99, 0xcc, 0x00)
  val holoBlue = Color.rgb(0x33, 0xb5, 0xe5)
  val holoYellow = Color.rgb(0xff, 0xbb, 0x33)
}

class MainActivity extends SActivity with Observable {
  import LCamera._

  override implicit val loggerTag = LoggerTag("lcamera")

  var performCapture: Option[(() => Unit)] = None

  onCreate {
    val condensedTypeface = Typeface.create("sans-serif-condensed", Typeface.NORMAL)

    implicit val cameraManager = getSystemService(Context.CAMERA_SERVICE).asInstanceOf[CameraManager]
    val lcamera = NoneVar[LCamera]

    val intent = getIntent
    val action = intent.getAction
    val isImageCaptureActivity = action == MediaStore.ACTION_IMAGE_CAPTURE

    val saveDng = Var(true)
    val minBursts = 2
    val maxBursts = 20
    val numBursts = Var(3)
    val burstCaptureRawYuv = Var[RawOrYuv](Yuv)
    val exposureBracketing = Var(0)
    val isPhotoSession = Rx { lcamera() exists { camera => camera.captureSession() flatMap { _.toOption } exists { _.isInstanceOf[camera.PhotoSession] } } }
    val isBurstSession = Rx { lcamera() exists { camera => camera.captureSession() flatMap { _.toOption } exists { _.isInstanceOf[camera.BurstSession] } } }
    val isBulbSession  = Rx { lcamera() exists { camera => camera.captureSession() flatMap { _.toOption } exists { _.isInstanceOf[camera.BulbSession ] } } }
    val isVideoSession = Rx { lcamera() exists { camera => camera.captureSession() flatMap { _.toOption } exists { _.isInstanceOf[camera.VideoSession] } } }

    val autoFocus = Var(true)
    val focusDistance = Var(0f)
    val focus = Rx[Focus] { if (autoFocus()) AutoFocus else new ManualFocus(focusDistance()) }

    val autoExposure = Var(true)
    val isos = Vector(40, 50, 80, 100, 200, 300, 400, 600, 800, 1000, 1600, 2000, 3200, 4000, 6400, 8000, 10000)
    val validIsos = Rx { lcamera().toList flatMap { camera => isos filter { camera.isoRange contains _ }} }
    val iso = Var(100)
    val exposureTimes = Vector[Double](1.2, 2, 4, 6, 8, 15, 30, 60, 100, 125, 250, 500, 750, 1000, 1500, 2000, 3000, 4000, 5000, 6000, 8000, 10000, 20000, 30000, 75000) map { d => (1000000000l / d).toLong }
    val validExposureTimes = Rx { lcamera().toList flatMap { camera => exposureTimes filter { camera.exposureTimeRange contains _ }} }
    val exposureTime = Var(1000000000l / 30)
    val exposure = Rx[Exposure] { if (autoExposure()) AutoExposure else new ManualExposure(exposureTime(), iso()) }

    observe { for { (focus, exposure, session) <- Rx { (focus(), exposure(), lcamera() flatMap { _.captureSession() flatMap { _.toOption } } ) } } {
      session foreach { _.setupPreview(focus, exposure) }
    } }

    onResume { observe { (new LCameraManager).openLCamera("0") foreach { lcamera() = _ }} }
    onPause  { lcamera() foreach { _.close() } }

    val videoConfigurations = List(
      new VideoConfiguration(3840, 2160, 30, 65000000),
      new VideoConfiguration(3264, 2448, 30, 65000000),
      new VideoConfiguration(3264, 2448, 30, 35000000),
      new VideoConfiguration(1920, 1080, 60, 16000000),
      new VideoConfiguration(1920, 1080, 30, 8000000),
      new VideoConfiguration(1600, 1200, 60, 16000000),
      new VideoConfiguration(1600, 1200, 30, 8000000),
      new VideoConfiguration(1280, 720, 60, 10000000),
      new VideoConfiguration(1280, 720, 30, 5000000),
      new VideoConfiguration(800, 600, 120, 5000000))

    val availableVideoConfigurations = Rx { lcamera().toList flatMap { camera => videoConfigurations filter { vc =>
      val size = new Size(vc.width, vc.height)
      size <= camera.rawSize && camera.yuvSizes.contains(size) && vc.fps <= camera.rawFps
    } } }

    val userVideoConfiguration = Var(videoConfigurations(0))
    val videoConfiguration = Rx { availableVideoConfigurations() find { _ == userVideoConfiguration() } orElse availableVideoConfigurations().lift(0) }

    val orientationVar = Var(windowManager.getDefaultDisplay.getRotation)

    val orientationEventListener = new OrientationEventListener(this) {
      override def onOrientationChanged(deg: Int) = {
        val newOrientation =
          if (deg >= 0 && deg < 45 || deg >= 315 && deg < 360) Surface.ROTATION_0
          else if (deg >= 45 && deg < 135) Surface.ROTATION_270
          else if (deg >= 135 && deg < 225) Surface.ROTATION_180
          else if (deg >= 225 && deg < 315) Surface.ROTATION_90
          else Surface.ROTATION_0

        debug(newOrientation.toString)
        if (orientationVar() != newOrientation) {
          orientationVar() = newOrientation // FIXME: Re-create video session
        }
      }
    }

    onResume { orientationEventListener.enable() }
    onPause  { orientationEventListener.disable() }

    contentView = new SRelativeLayout {
      val textureView = new STextureView {
        onTouch((v, e) => {
          if (e.getActionMasked == MotionEvent.ACTION_DOWN) {
            lcamera() foreach { camera =>
              camera.captureSession() flatMap { _.value flatMap { _.toOption } } foreach {
                case session =>
                  if (autoFocus() || autoExposure()) {
                    val meteringRectangleSize = 300
                    val left = camera.activeArraySize.left
                    val right = camera.activeArraySize.right
                    val top = camera.activeArraySize.top
                    val bottom = camera.activeArraySize.bottom

                    val x = e.getX / v.getWidth
                    val y = e.getY / v.getHeight
                    val mr = new MeteringRectangle(
                      0 max (left + (right - left) * y - meteringRectangleSize / 2).round,
                      0 max (bottom - (bottom - top) * x - meteringRectangleSize / 2).round,
                      meteringRectangleSize, meteringRectangleSize, 1
                    )

                    session.triggerMetering(mr, focus(), exposure())
                  } } }
            true
          } else false
        })
      }

      val previewSurface = Rx { for { camera <- lcamera() ; texture <- textureView.surfaceTexture() } yield {
        val textureSize = camera.streamConfigurationMap.getOutputSizes(texture.getClass).filter(sz => sz <= camera.rawSize && sz <= new Size(1600, 1200))(0) // TODO: Obtain the size from camera configuration and screen size.
        texture.setDefaultBufferSize(textureSize.getWidth, textureSize.getHeight)
        new Surface(texture)
      }}

      observe { for { (cameraOption, _) <- Rx { (lcamera(), previewSurface()) } ; camera <- cameraOption } {
        if (textureView.isAvailable) {
          textureView.setTransform {
            val textureSize = camera.streamConfigurationMap.getOutputSizes(textureView.getSurfaceTexture.getClass).filter(sz => sz <= camera.rawSize && sz <= new Size(1600, 1200))(0)
            val viewRect = new RectF(0, 0, textureView.width, textureView.height)
            val bufferRect = new RectF(0, 0, textureSize.getHeight, textureSize.getWidth)
            bufferRect.offset(viewRect.centerX - bufferRect.centerX, viewRect.centerY - bufferRect.centerY)
            val matrix = new Matrix()
            matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.CENTER)
            // matrix.postRotate(rotation * 90, viewRect.centerX, viewRect.centerY) // TODO: Rotate by the difference of screen orientation and camera orientation
            matrix
          }
        }
      }}

      observe { for { (previewSurface, session) <- Rx { ( previewSurface(), lcamera() flatMap { _.captureSession() } ) } } {
        previewSurface foreach { surface => if (session.isEmpty) { lcamera() foreach { _.openPhotoSession(surface) } } }
      } }

      val captureButton = new Fab(ctx) with TraitImageButton[Fab] {
        val basis = this
        def fadeTo(color: Int, drawable: Int): Unit = {
          imageDrawable = drawable
          val anim = ObjectAnimator.ofArgb(this, "backgroundColor", background.asInstanceOf[ColorDrawable].getColor, color)
          anim.addListener(new AnimatorListenerAdapter() {
            override def onAnimationEnd(animator: Animator): Unit = { backgroundColor = color }
          })
          anim.setDuration(150)
          anim.start()
        }

        backgroundColor = Colors.grey300
        scaleType = ScaleType.FIT_CENTER
        performCapture = Some { () => performClick() }
        onClick { lcamera() foreach { camera => camera.captureSession() flatMap { _.toOption } match {
          case Some(ps: camera.PhotoSession) =>
            val time = new Time
            time.setToNow()
            val orientation = orientationVar()
            ps.capture(focus(), exposure(), orientation, { (result, jpegImage, rawImage) => {
              if (isImageCaptureActivity) {
                val saveUri: Option[Uri] = Option(intent.getExtras.getParcelable[Uri](MediaStore.EXTRA_OUTPUT))
                handleCaptureIntent(saveUri, jpegImage)
              } else {
                val filePathBase = Utils.createPathIfNotExist(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM) + "/Camera/") + time.format("IMG_%Y%m%d_%H%M%S")

                saveJpegFile(s"$filePathBase.jpg", jpegImage)
                if (saveDng()) {
                  saveDngFile(s"$filePathBase.dng", camera.characteristics, result, rawImage, orientation)
                }
              }
            }})
          case Some(bs: camera.BurstSession) =>
            val time = new Time
            time.setToNow()
            val filePathBase = Utils.createPathIfNotExist(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM) + "/Camera/") + time.format("IMG_%Y%m%d_%H%M%S")
            val orientation = orientationVar()

            val requests = for (n <- 1 to numBursts()) yield {
              val exp = if (exposureBracketing() == 0) exposure() else {
                val computeExposureTime = (t: Long) => camera.exposureTimeRange.clamp((t * Math.pow(2, (numBursts() / 2 - n) * (exposureBracketing() / 3.0))).toLong)
                exposure() match {
                  case AutoExposure => ManualExposure(computeExposureTime(bs.lastExposureTime()), bs.lastIso())
                  case me: ManualExposure => me.copy(exposureDuration = computeExposureTime(me.exposureDuration))
                } }

              bs.Request(focus(), exp,
                bs.rawYuv match {
                  case Raw => (result, image) => saveDngFile(s"${filePathBase}_$n.dng", camera.characteristics, result, image, orientation)
                  case Yuv => (result, image) => saveYuvAsJpeg(s"${filePathBase}_$n.jpg", image)
                })
            }

            bs.burstCapture(requests.toList, orientation)
          case Some(bs: camera.BulbSession) => if (!bs.capturing()) {
            val time = new Time
            time.setToNow()
            val filePathBase = Utils.createPathIfNotExist(Environment.getExternalStoragePublicDirectory(Environment.DIRECTORY_DCIM) + "/Camera/") + time.format("IMG_%Y%m%d_%H%M%S")
            val orientation = orientationVar()

            bs.startCapturing(focus(), exposure(), orientation, (result, image, n) => saveDngFile(s"${filePathBase}_$n.dng", camera.characteristics, result, image, orientation))
          } else bs.stopCapturing()
          case Some(vs: camera.VideoSession) =>
            if (!vs.recording()) {
              vs.startRecording(focus(), exposure())
            } else {
              vs.stopRecording()
              for { surface <- previewSurface() ; vc <- videoConfiguration() } {
                camera.openVideoSession(surface, vc, orientationVar())
              }
            }
          case _ =>
        }}}

        observe {
          Rx {
            lcamera() match {
              case Some(camera) => camera.captureSession() flatMap { _.toOption } match {
                case Some(ps: camera.PhotoSession) => if (ps.capturing()) (Colors.grey300, R.drawable.ic_camera, false) else (Colors.blueA400, R.drawable.ic_camera, true)
                case Some(bs: camera.BurstSession) => if (bs.capturing()) (Colors.grey300, R.drawable.ic_camera, false) else (Colors.holoBlue, R.drawable.ic_camera, true)
                case Some(bs: camera.BulbSession)  => if (bs.capturing()) (Colors.holoRed, R.drawable.ic_av_stop, true) else (Colors.holoYellow, R.drawable.ic_bulb, true)
                case Some(vs: camera.VideoSession) => if (vs.recording()) (Colors.holoRed, R.drawable.ic_av_stop, true) else (Colors.holoGreen, R.drawable.ic_video, true)
                case _ => (Colors.grey300, R.drawable.ic_camera, false) // FIXME
              }
              case _ => (Colors.grey300, R.drawable.ic_camera, false) // FIXME
            }
          } foreach {
            case (color, icon, en) =>
              enabled = en
              fadeTo(color, icon)
          }
        }
      }

      val cpv = new CircularProgressView(ctx) with TraitView[CircularProgressView] with Observable {
        val basis = this
        setIndeterminate(true)
        setThickness(4.dip)
        setColor(Colors.orange500)
        startAnimation()

        observe { Rx {
          lcamera() match {
            case Some(camera) => camera.captureSession() flatMap { _.toOption } match {
              case Some(ps: camera.PhotoSession) => ps.capturing()
              case Some(bs: camera.BurstSession) => bs.capturing()
              case _ => false
            }
            case _ => false
          }
        } foreach { c => visibility = if (c) View.VISIBLE else View.INVISIBLE } }
      }

      val showSettingsDialog = () => {
        new AlertDialogBuilder {
          setView(new SVerticalLayout {
            padding(24.dip, 16.dip, 24.dip, 16.dip)

            += (new STextView {
              text = "Photo Mode"
              textColor = Colors.grey600
              textSize = 14.sp
              gravity = Gravity.CENTER_VERTICAL
            }.<<(MATCH_PARENT, 32.dip).>>)

            += (new SRelativeLayout {
              padding(0.dip, 16.dip, 0.dip, 16.dip)

              += (new STextView {
                text = "Save DNG"
                textColor = Colors.grey300
                textSize = 16.sp
              }.<<.wrap.alignParentLeft.centerVertical.>>)

              += (new SCheckBox {
                observe { saveDng foreach setChecked }
                onCheckedChanged { (v: View, checked: Boolean) => saveDng() = checked }
              }.<<.wrap.alignParentRight.centerVertical.>>)
            })

            += (new STextView {
              text = "Burst Mode"
              textColor = Colors.grey600
              textSize = 14.sp
              gravity = Gravity.CENTER_VERTICAL
            }.<<(MATCH_PARENT, 32.dip).>>)

            += (new SLinearLayout {
              gravity = Gravity.CENTER_VERTICAL
              padding(0.dip, 16.dip, 0.dip, 16.dip)

              += (new STextView {
                text = "No. of Images"
                textColor = Colors.grey300
                textSize = 16.sp
              }.<<.fw.Weight(1.0f).>>)

              += (makePrevButton(Rx { numBursts() > minBursts }, { numBursts() = Math.max(numBursts() - 1, minBursts) }).wrap)
              += (new STextView {
                observe { numBursts foreach { n => text = n.toString } }
                gravity = Gravity.CENTER
              }.wrap)
              += (makeNextButton(Rx { numBursts() < maxBursts }, { numBursts() = Math.min(numBursts() + 1, maxBursts) }).wrap)
            })

            += (new SLinearLayout {
              gravity = Gravity.CENTER_VERTICAL
              padding(0.dip, 16.dip, 0.dip, 16.dip)

              def evToString(ev: Int): String = {
                if (ev == 0) "Off"
                else if (ev % 3 == 0) s"${ev / 3} EV"
                else s"$ev/3 EV"
              }

              += (new STextView {
                text = "Exp. Bracketing"
                textColor = Colors.grey300
                textSize = 16.sp
              }.<<.fw.Weight(1.0f).>>)

              += (makePrevButton(Rx { exposureBracketing() > 0 }, { exposureBracketing() = Math.max(exposureBracketing() - 1, 0) }).wrap)
              += (new STextView {
                observe { exposureBracketing foreach { ev => text = evToString(ev) } }
                gravity = Gravity.CENTER
              }.<<(48.sp, WRAP_CONTENT).>>)
              += (makeNextButton(Rx { exposureBracketing() < 6 }, { exposureBracketing() = Math.min(exposureBracketing() + 1, 6) }).wrap)
            })

            += (new SRelativeLayout {
              padding(0.dip, 16.dip, 0.dip, 16.dip)

              += (new STextView {
                text = "Save DNG"
                textColor = Colors.grey300
                textSize = 16.sp
              }.<<.wrap.alignParentLeft.centerVertical.>>)

              += (new SCheckBox {
                observe { burstCaptureRawYuv foreach {
                  case Raw => checked = true
                  case Yuv => checked = false
                }}
                onCheckedChanged { (v: View, checked: Boolean) => {
                  burstCaptureRawYuv() = if (checked) Raw else Yuv
                  for { camera <- lcamera() ; surface <- previewSurface() } {
                    if (isBurstSession()) camera.openBurstSession(surface, burstCaptureRawYuv())
                  }}
                }
              }.<<.wrap.alignParentRight.centerVertical.>>)
            })

            += (new STextView {
              text = "Video Mode"
              textColor = Colors.grey600
              textSize = 14.sp
              gravity = Gravity.CENTER_VERTICAL
            }.<<(MATCH_PARENT, 32.dip).>>)

            += (new SVerticalLayout {
              padding(0.dip, 16.dip, 0.dip, 16.dip)

              += (new STextView {
                text = "Video Resolution"
                textColor = Colors.grey300
                textSize = 16.sp
              }.wrap)

              += (new STextView {
                textSize = 12.sp
                textColor = Colors.grey600
                observe { videoConfiguration foreach {
                  case Some(vc) => text = vc.toString
                  case None => text = "N/A"
                } }
              }.wrap)

              onClick {
                new AlertDialogBuilder("Video Resolution") {
                  val videoConfigurationAdapter: ArrayAdapter[VideoConfiguration] = new SArrayAdapter(videoConfigurations.toArray) {
                    override def isEnabled(which: Int): Boolean = availableVideoConfigurations() contains videoConfigurations(which)

                    override def getView(which: Int, convertView: View, parent: ViewGroup): View =
                      new STextView {
                        text = videoConfigurations(which).toString
                        textColor = if (videoConfigurationAdapter.isEnabled(which)) {
                          if (videoConfiguration() contains videoConfigurations(which)) Colors.orange500 else Colors.grey300
                        } else {
                          Colors.grey600
                        }
                        textSize = 16.sp
                      }.padding(16.dip)
                  }

                  setAdapter(videoConfigurationAdapter, new DialogInterface.OnClickListener {
                    override def onClick(dialog: DialogInterface, which: Int): Unit = { userVideoConfiguration() = videoConfigurations(which) }
                  })
                }.show()
              }
            })

            += (new STextView {
              text = "Help & GitHub"
              textColor = Colors.grey300
              textSize = 16.sp
              gravity = Gravity.CENTER_VERTICAL
              onClick { openUri("https://www.github.com/pkmx/lcamera") }
            }.<<(MATCH_PARENT, 32.dip).>>)
          })
        }.show()
      }

      class Toolbar extends SLinearLayout with Observable {
        clickable = true
        backgroundColor = Colors.grey800
        gravity = Gravity.CENTER
        visibility = View.INVISIBLE
      }

      val afView = new Toolbar {
        += (new STextView {
          observe { autoFocus foreach { af => text = if (af) "AF" else "MF" } }
          observe { autoFocus foreach { af => textColor = if (af) Colors.grey600 else Colors.orange500 } }
          onClick { autoFocus() = !autoFocus() }
          typeface = Typeface.DEFAULT_BOLD
          textSize = 16.sp
        }.padding(8.dip, 16.dip, 16.dip, 16.dip).wrap)
        += (new SSeekBar {
          observe { lcamera foreach { _ foreach { camera => max = (camera.minFocusDistance * 100).round } } }
          observe { autoFocus foreach { af => enabled = !af } }
          observe { focusDistance.foreach { fd => setProgress { (fd * 100).round } } }
          onProgressChanged { (seekbar: SeekBar, value: Int, fromUser: Boolean) => {
            if (fromUser)
              focusDistance() = value.toFloat / 100
          }}
        }.padding(8.dip, 8.dip, 8.dip, 8.dip).<<.fw.Weight(1.0f).>>)
      }.padding(16.dip, 0, 16.dip, 0)

      val aeView = new Toolbar {
        += (new STextView {
          observe { lcamera foreach { _ foreach { camera => text = f"f/${camera.characteristics.get(LENS_INFO_AVAILABLE_APERTURES)(0)}%.1f" } } }
          typeface = condensedTypeface
          textColor = Colors.grey600
        }.padding(8.dip, 16.dip, 8.dip, 16.dip).wrap)

        val prevExposureTime = Rx { (validExposureTimes() filter { _ > exposureTime() }).lastOption }
        += (makePrevButton(Rx { !autoExposure() && prevExposureTime().nonEmpty }, { prevExposureTime() foreach { exposureTime() = _ } }))
        += (new STextView {
          typeface = condensedTypeface
          val lastExposureTime = Rx { lcamera() flatMap { _.captureSession() flatMap { _.toOption } } map { _.lastExposureTime() } getOrElse 1000000000l }
          observe { Rx { if (autoExposure()) lastExposureTime() else exposureTime() } foreach { t => text = if (t >= 500000000) f"${t / 1000000000.0}%.1f″" else s"1/${1000000000 / t}" } }
          observe { autoExposure foreach { ae => textColor = if (ae) Colors.grey600 else Colors.orange500 } }
          onClick { autoExposure() = !autoExposure() }
        }.padding(0.dip, 16.dip, 0.dip, 16.dip).wrap)
        val nextExposureTime = Rx { validExposureTimes() find { _ < exposureTime() } }
        += (makeNextButton(Rx { !autoExposure() && nextExposureTime().nonEmpty }, { nextExposureTime() foreach { exposureTime() = _ } }))

        val prevIso = Rx { (validIsos() filter { _ < iso() }).lastOption }
        += (makePrevButton(Rx { !autoExposure() && prevIso().nonEmpty }, { prevIso() foreach { iso() = _ } }))
        += (new STextView {
          typeface = condensedTypeface
          val lastIso = Rx { lcamera() flatMap { _.captureSession() flatMap { _.toOption } } map { _.lastIso() } getOrElse 100 }
          observe { Rx { if (autoExposure()) lastIso() else iso() } foreach { v => text = s"ISO $v" } }
          observe { autoExposure foreach { ae => textColor = if (ae) Colors.grey600 else Colors.orange500 } }
          onClick { autoExposure() = !autoExposure() }
        }.padding(0.dip, 16.dip, 0.dip, 16.dip).wrap)
        val nextIso = Rx { validIsos() find { _ > iso() } }
        += (makeNextButton(Rx { !autoExposure() && nextIso().nonEmpty }, { nextIso() foreach { iso() = _ } }))
      }

      val modeView = new Toolbar with Observable {
        val rxCanSwitchMode = Rx { lcamera() match {
          case Some(camera) => camera.captureSession() flatMap { _.toOption } match {
            case Some(ps: camera.PhotoSession) => !ps.capturing()
            case Some(bs: camera.BurstSession) => !bs.capturing()
            case Some(bs: camera.BulbSession) => !bs.capturing()
            case Some(vs: camera.VideoSession) => !vs.recording()
            case None => true
          }
          case None => false
        } }

        def makeModeButton(drawableRes: Int, isCurrentMode: Rx[Boolean], f: (LCamera, Surface) => Unit): SImageButton =
          makeImageButton(drawableRes, Rx { rxCanSwitchMode() && !isCurrentMode() }, Rx { if (isCurrentMode()) Some(Colors.orange500) else if (!rxCanSwitchMode()) Some(Colors.grey600) else None}, {
            for { camera <- lcamera() ; previewSurface <- previewSurface() } { f(camera, previewSurface) }
          }).padding(8.dip).<<.marginLeft(8.dip).marginRight(8.dip).wrap.>>

        += (makeModeButton(R.drawable.ic_photo_mode, isPhotoSession, { (camera, surface) => camera.openPhotoSession(surface) }))
        += (makeModeButton(R.drawable.ic_burst_mode, isBurstSession, { (camera, surface) => camera.openBurstSession(surface, burstCaptureRawYuv(), maxBursts) }))
        += (makeModeButton(R.drawable.ic_bulb_mode , isBulbSession , { (camera, surface) => camera.openBulbSession(surface) }))
        += (makeModeButton(R.drawable.ic_video_mode, isVideoSession, { (camera, surface) => videoConfiguration() foreach { vc => camera.openVideoSession(surface, vc, orientationVar()) } }))
      }

      val bottomBar = new SLinearLayout {
        backgroundColor = Colors.grey800
        gravity = Gravity.CENTER

        val currentToolbar = NoneVar[View]
        val toolbars = List(afView, aeView, modeView)
        onBackPressedBody = () => if (currentToolbar().isEmpty) false else { currentToolbar() = None ; true }

        observe { currentToolbar foreach {
          case Some(cv) =>
            for { v <- toolbars if v.enabled && v != cv } { slideDownHide(v) }
            slideUpShow(cv)
          case None => for { v <- toolbars if v.enabled } { slideDownHide(v) }
        }}

        def toggleToolbar(v: View): Unit = { currentToolbar() = if (currentToolbar() == Some(v)) None else Some(v) }

        def makeButton(drawableRes: Int, view: View) = makeImageButton(drawableRes, Rx { true }, Rx { if (currentToolbar() == Some(view)) Some(Colors.orange500) else None }, toggleToolbar(view)).padding(16.dip).wrap
        += (makeButton(R.drawable.ic_focus, afView))
        += (makeButton(R.drawable.ic_exposure, aeView))
        += (new SRelativeLayout {
          += (captureButton.<<(56.dip, 56.dip).centerInParent.>>)
          += (cpv.<<(60.dip, 60.dip).centerInParent.>>)
        }.<<(80.dip, 80.dip).>>)
        += (new SImageView {
          gravity = Gravity.CENTER
          backgroundResource = resolveAttr(android.R.attr.selectableItemBackground)
          observe { Rx { lcamera() match {
            case Some(camera) => camera.captureSession() flatMap { _.toOption } match {
              case Some(_: camera.PhotoSession) => R.drawable.ic_photo_mode
              case Some(_: camera.BurstSession) => R.drawable.ic_burst_mode
              case Some(_: camera.BulbSession) => R.drawable.ic_bulb_mode
              case Some(_: camera.VideoSession) => R.drawable.ic_video_mode
              case None => R.drawable.ic_photo_mode
            }
            case None => R.drawable.ic_photo_mode
          } } foreach { imageDrawable = _ } }
          onClick { toggleToolbar(modeView) }
        }.padding(16.dip).wrap)
        += (new SImageView {
          gravity = Gravity.CENTER
          backgroundResource = resolveAttr(android.R.attr.selectableItemBackground)
          imageDrawable = R.drawable.ic_settings
          onClick { showSettingsDialog() }
        }.padding(16.dip).wrap)
      }

      += (textureView.<<.alignParentLeft.alignParentRight.alignParentTop.above(bottomBar).>>)
      for { v <- List(afView, aeView, modeView) } {
        += (v.<<.fw.alignParentLeft.alignParentRight.above(bottomBar).>>)
      }
      += (bottomBar.<<(MATCH_PARENT, 96.dip).alignParentLeft.alignParentRight.alignParentBottom.>>)
    }

    getWindow.addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON)

    val prefs = new Preferences(getSharedPreferences("lcamera", Context.MODE_PRIVATE))
    prefs.Boolean.autoFocus.foreach { autoFocus() = _ }
    prefs.Float.focusDistance.foreach { focusDistance() = _ }
    prefs.Boolean.autoExposure.foreach { autoExposure() = _ }
    prefs.Int.iso.foreach { iso() = _ }
    prefs.Long.exposureTime.foreach { exposureTime() = _ }
    prefs.Int.numBursts.foreach { numBursts() = _ }
    prefs.Int.exposureBracketing.foreach { exposureBracketing() = _ }
    for { vcWidth <- prefs.Int.vcWidth
          vcHeight <- prefs.Int.vcHeight
          vcFps <- prefs.Int.vcFps
          vcBitrate <- prefs.Int.vcBitrate } {
      val vc = new VideoConfiguration(vcWidth, vcHeight, vcFps, vcBitrate)
      if (availableVideoConfigurations() contains vc)
        userVideoConfiguration() = vc
    }
    prefs.Boolean.saveDng.foreach { saveDng() = _ }
    prefs.Boolean.burstCaptureRawYuv.foreach { b => burstCaptureRawYuv() = if (b) Raw else Yuv }

    onStop {
      prefs.autoFocus = autoFocus()
      prefs.focusDistance = focusDistance()
      prefs.autoExposure = autoExposure()
      prefs.iso = iso()
      prefs.exposureTime = exposureTime()
      prefs.numBursts = numBursts()
      prefs.exposureBracketing = exposureBracketing()
      prefs.vcWidth = userVideoConfiguration().width
      prefs.vcHeight = userVideoConfiguration().height
      prefs.vcFps = userVideoConfiguration().fps
      prefs.vcBitrate = userVideoConfiguration().bitrate
      prefs.saveDng = saveDng()
      prefs.burstCaptureRawYuv = burstCaptureRawYuv() match { case Raw => true ; case Yuv => false }
    }

    observe { for { cameraOpt <- lcamera ; camera <- cameraOpt } {
      val capabilities = camera.characteristics.get(REQUEST_AVAILABLE_CAPABILITIES)
      val requiredCapabilities = List(
        REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR,
        REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING,
        REQUEST_AVAILABLE_CAPABILITIES_RAW)

      if (!(requiredCapabilities forall { capabilities contains _ })) {
        toast("L Camera is not supported on your device")
        finish()
      }
    }}
  }

  var onBackPressedBody = () => false

  override def onBackPressed(): Unit = {
    if (!onBackPressedBody()) {
      super.onBackPressed()
    }
  }

  override def onKeyDown(keyCode: Int, event: KeyEvent): Boolean = {
    if (keyCode == KeyEvent.KEYCODE_VOLUME_UP || keyCode == KeyEvent.KEYCODE_VOLUME_DOWN) {
      performCapture foreach { _() }
      performCapture.nonEmpty
    } else {
      super.onKeyDown(keyCode, event)
    }
  }

  def saveDngFile(filePath: String, characteristics: CameraCharacteristics, result: TotalCaptureResult, image: Image, orientation: Int): Unit = {
    val dngCreator = new DngCreator(characteristics, result).setOrientation(orientation)
    dngCreator.writeImage(new FileOutputStream(filePath), image)
    dngCreator.close()
    mediaScan(filePath, ACTION_NEW_PICTURE)
    debug(s"DNG saved: $filePath")
  }

  def saveJpegFile(filePath: String, image: Image): Unit = {
    val jpegBuffer = image.getPlanes()(0).getBuffer
    val bytes = new Array[Byte](jpegBuffer.capacity)
    jpegBuffer.get(bytes)
    new FileOutputStream(filePath).write(bytes)
    mediaScan(filePath, ACTION_NEW_PICTURE)
    debug(s"JPEG saved: $filePath")
  }

  def handleCaptureIntent(uriOpt: Option[Uri], image: Image): Unit = {
    val imageBuffer = image.getPlanes()(0).getBuffer
    val bytes = new Array[Byte](imageBuffer.capacity)
    imageBuffer.get(bytes)

    uriOpt match {
      case Some(saveUri) =>
        ignoring(classOf[FileNotFoundException]) {
          val outputStream = contentResolver.openOutputStream(saveUri)
          outputStream.write(bytes)
          outputStream.close()
          setResult(RESULT_OK)
          finish()
          outputStream.close()
        }
      case None =>
        // TODO: Resized bitmap for "inline-data" intent
        setResult(RESULT_CANCELED, new Intent())
        finish()
    }
  }

  def saveYuvAsJpeg(filePath: String, image: Image): Unit = {
    val bytes = List(0, 2) map { n => byteBufferToByteArray(image.getPlanes()(n).getBuffer) } reduceLeft { _ ++ _ }
    val yuvImage = new YuvImage(bytes, ImageFormat.NV21, image.getWidth, image.getHeight, null)

    val outputStream = new FileOutputStream(filePath)
    val rect = new Rect(0, 0, image.getWidth, image.getHeight)
    debug(s"${rect.width} ${rect.height}")
    yuvImage.compressToJpeg(rect, 100, outputStream)
    image.close()
    outputStream.close()
    mediaScan(filePath, ACTION_NEW_PICTURE)
    debug(s"JPEG saved: $filePath")
  }

  def makeImageButton(drawableRes: Int, rxEnable: Rx[Boolean], rxColor: Rx[Option[Int]], f: => Unit): SImageButton = new SImageButton {
    backgroundResource = resolveAttr(android.R.attr.selectableItemBackground)
    observe { rxEnable foreach { enabled = _ } }
    observe { rxColor foreach { oc => imageDrawable = oc map { colorTintDrawable(drawableRes, _) } getOrElse drawableRes.r2Drawable } }
    onClick(f)
  }

  def makePrevButton(rxEnable: Rx[Boolean], f: => Unit): SImageButton = makeImageButton(R.drawable.ic_navigation_chevron_left,  rxEnable, Rx { if (rxEnable()) None else Some(Colors.grey600)}, f).padding(4.dip)
  def makeNextButton(rxEnable: Rx[Boolean], f: => Unit): SImageButton = makeImageButton(R.drawable.ic_navigation_chevron_right, rxEnable, Rx { if (rxEnable()) None else Some(Colors.grey600)}, f).padding(4.dip)

  def colorTintDrawable(drawable: Int, color: Int): Drawable = {
    val d = drawable.mutate()
    d.setColorFilter(color, PorterDuff.Mode.SRC_IN)
    d
  }

  def resolveAttr(attr: Int): Int = {
    val ta = obtainStyledAttributes(Array[Int](attr))
    val resId = ta.getResourceId(0, 0)
    ta.recycle()
    resId
  }
}